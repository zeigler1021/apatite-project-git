---
title: "4_Apatite Data_Graveyard "
output: html_notebook
---



###Plotting Code

###Plotting uncertainty in residuals code. I play with  dplyr here a lot

Exploring 'uncertainty' in Ft correction: 
## Rare vs. Common
```{r}
res_plotting %>%
  filter(sign == "total") %>%
  ggplot() +
  geom_errorbar(aes(x = value, ymax = (median_res + sd_res), ymin = (median_res - sd_res))) +
  geom_point(aes(value, median_res)) +
  labs(x = "Size Category", y = "Residual")
```

#Ft
```{r}
apatite %>%
  filter(gem.geo == "C") %>%
ggplot(aes(j.w1, percent.diff, color = ri, )) +
  scale_color_manual(values = cb3) +
  geom_point() +
  geom_abline(slope = 0, intercept = 0) +
  labs(x = "Max Width", y = "Residuals as % Difference", title = "Ft Residuals as % difference, C grains, Roughness")
```

#Volume
```{r}
apatite %>%
  #filter(gem.geo == "AB") %>%
ggplot(aes(j.w1, percent.diff, color = ri, key = sample)) +
  scale_color_manual(values = cb3) +
  geom_point() +
  geom_abline(slope = 0, intercept = 0) +
  labs(x = "Max Width", y = "Residuals as % Difference", title = "Volume Residuals as % difference, all grains, Roughness")

#ggplotly(p, tooltip = c("key"))
```


```{r}
ggplot(c_all, aes(j.w1, c_all_residuals_ft[,1001], color = size.cat)) +
  geom_point(size = 2) +
  geom_abline(slope = 0, intercept = 0, size = 1.1) +
  scale_color_manual(values = qual_color_random) +
  labs(x = "Grain Width (µm)", y= "Residuals", title = "All Ellipsoid Grains, Colored by Rare vs. Common") +
    geom_segment(aes(x = 40, xend = 51,
                     y = all_res[[3,2]], yend = all_res[[3,2]]),
                 color = "red") + #small,rare,all
    geom_segment(aes(x = 51, xend = 101, 
                     y = all_res[[1,2]], yend =all_res[[1,2]]), 
                 color = "red") + #common,all
    geom_segment(aes(x = 101, xend = 161, 
                     y = all_res[[2,2]], yend = all_res[[2,2]]), 
                 color = "red") + #large,rare,all
    geom_segment(aes(x = 40, xend = 51,
                     y = pos_res[[3,2]], yend = pos_res[[3,2]]),
                 linetype = 3, color = "black") + #small,rare,pos
    geom_segment(aes(x = 40, xend = 51,
                     y = neg_res[[3,2]], yend = neg_res[[3,2]]),
                 linetype = 3, color = "black") + #small,rare,neg
    geom_segment(aes(x =51, xend = 101, 
                     y = pos_res[[1,2]], yend = pos_res[[1,2]]), 
                 linetype = 3, color = "black") + #common,pos
    geom_segment(aes(x =51, xend = 101, 
                     y = neg_res[[1,2]], yend = neg_res[[1,2]]), 
                 linetype = 3, color = "black") + #common,neg
    geom_segment(aes(x = 101, xend = 161, 
                     y = pos_res[[2,2]], yend = pos_res[[2,2]]), 
                 linetype = 3, color = "black") + #large,rare,post
    geom_segment(aes(x = 101, xend = 161, 
                     y = neg_res[[2,2]], yend = neg_res[[2,2]]), 
                 linetype = 3, color = "black") #large,rare,neg

#ggplotly(p, tooltip = c("key"))
#outlier at -0.05 and w = 100 is 16MFs05,2a1,7
```

## Size Categories
```{r}
ggplot(c_all, aes(j.w1, c_all_residuals_volume[,1001], color = size.name)) +
  #xlim(35,110) + ylim(-350, 350) +
  geom_point(size = 2) +
  geom_abline(slope = 0, intercept = 0, size = 1.1) +
  scale_color_manual(values = qual_color_random) +
  labs(x = "Grain Width (µm)", y= "Residuals", title = "All Ellipsoid Grains, Colored by Size Categories") +
    # geom_segment(aes(x = 40, xend = 51,
    #                  y = all_res[[1,2]], yend = all_res[[1,2]]),
    #              color = "red") + #small,rare,all
    geom_segment(aes(x = 51, xend = 61, 
                     y = all_res[[2,2]], yend =all_res[[2,2]]), 
                 color = "red") + #small,common,all
    geom_segment(aes(x = 61, xend = 81, 
                     y = all_res[[3,2]], yend =all_res[[3,2]]), 
                 color = "red") + #common,all
    geom_segment(aes(x = 81, xend = 101, 
                     y = all_res[[4,2]], yend = all_res[[4,2]]), 
                 color = "red") + #large,common,all
    geom_segment(aes(x = 101, xend = 111, 
                     y = all_res[[5,2]], yend = all_res[[5,2]]), 
                 color = "red") + #large,rare,all
  
    # geom_segment(aes(x = 40, xend = 51, 
    #                  y = pos_res[[1,2]], yend = pos_res[[1,2]]), 
    #              linetype = 3, color = "black") + #small,rare,pos
    # geom_segment(aes(x = 40, xend = 51, 
    #                  y = neg_res[[1,2]], yend = neg_res[[1,2]]), 
    #              linetype = 3, color = "black") + #small,rare,neg
    
    geom_segment(aes(x = 51, xend = 61, 
                     y = pos_res[[2,2]], yend = pos_res[[2,2]]), 
                 linetype = 3, color = "black") + #small,commmon,pos
    geom_segment(aes(x = 51, xend = 61, 
                     y = neg_res[[2,2]], yend = neg_res[[2,2]]), 
                 linetype = 3, color = "black") + #small,common,neg
  
    geom_segment(aes(x =61, xend = 81, 
                     y = pos_res[[3,2]], yend = pos_res[[3,2]]), 
                 linetype = 3, color = "black") + #common,pos
    geom_segment(aes(x =61, xend = 81, 
                     y = neg_res[[3,2]], yend = neg_res[[3,2]]), 
                 linetype = 3, color = "black") + #common,neg
  
    geom_segment(aes(x = 81, xend = 101, 
                     y = pos_res[[4,2]], yend = pos_res[[4,2]]), 
                 linetype = 3, color = "black") + #large,common,post
    geom_segment(aes(x = 81, xend = 101, 
                     y = neg_res[[4,2]], yend = neg_res[[4,2]]), 
                 linetype = 3, color = "black") + #large,common,neg
    geom_segment(aes(x = 101, xend = 111, 
                     y = pos_res[[5,2]], yend = pos_res[[5,2]]), 
                 linetype = 3, color = "black") + #large,rare,post
    geom_segment(aes(x = 101, xend = 111, 
                     y = neg_res[[5,2]], yend = neg_res[[5,2]]), 
                 linetype = 3, color = "black") #large,rare,neg
```


Exploring 'uncertainty' in Volume correction: 
## Rare vs. Common
```{r}
ggplot(ab_all, aes(j.w1, ab_all_residuals_volume[,1001], color = size.cat)) +
  geom_point(size = 2) +
  geom_abline(slope = 0, intercept = 0, size = 1.1) +
  scale_color_manual(values = qual_color_random) +
  labs(x = "Grain Width (µm)", y= "Residuals", title = "All Hexagonal Grains, Colored by Rare vs. Common") +
    geom_segment(aes(x = 40, xend = 51,
                     y = all_res[[3,2]], yend = all_res[[3,2]]),
                 color = "red") + #small,rare,all
    geom_segment(aes(x = 51, xend = 101, 
                     y = all_res[[1,2]], yend =all_res[[1,2]]), 
                 color = "red") + #common,all
    geom_segment(aes(x = 101, xend = 161, 
                     y = all_res[[2,2]], yend = all_res[[2,2]]), 
                 color = "red") + #large,rare,all
    geom_segment(aes(x = 40, xend = 51, 
                     y = pos_res[[3,2]], yend = pos_res[[3,2]]), 
                 linetype = 3, color = "black") + #small,rare,pos
    geom_segment(aes(x = 40, xend = 51, 
                     y = neg_res[[3,2]], yend = neg_res[[3,2]]), 
                 linetype = 3, color = "black") + #small,rare,neg
    geom_segment(aes(x =51, xend = 101, 
                     y = pos_res[[1,2]], yend = pos_res[[1,2]]), 
                 linetype = 3, color = "black") + #common,pos
    geom_segment(aes(x =51, xend = 101, 
                     y = neg_res[[1,2]], yend = neg_res[[1,2]]), 
                 linetype = 3, color = "black") + #common,neg
    geom_segment(aes(x = 101, xend = 161, 
                     y = pos_res[[2,2]], yend = pos_res[[2,2]]), 
                 linetype = 3, color = "black") + #large,rare,post
    geom_segment(aes(x = 101, xend = 161, 
                     y = neg_res[[2,2]], yend = neg_res[[2,2]]), 
                 linetype = 3, color = "black") #large,rare,neg

```

## Size Categories
```{r}
ggplot(ab_all, aes(j.w1, ab_all_residuals_volume[,1001], color = size.name)) +
  #xlim(35,110) + ylim(-350, 350) +
  geom_point(size = 2) +
  geom_abline(slope = 0, intercept = 0, size = 1.1) +
  scale_color_manual(values = qual_color_random) +
  labs(x = "Grain Width (µm)", y= "Residuals", title = "All Hexagonal Grains, Colored by Size Categories") +
    geom_segment(aes(x = 40, xend = 51,
                     y = all_res[[1,2]], yend = all_res[[1,2]]),
                 color = "red") + #small,rare,all
    geom_segment(aes(x = 51, xend = 61, 
                     y = all_res[[2,2]], yend =all_res[[2,2]]), 
                 color = "red") + #small,common,all
    geom_segment(aes(x = 61, xend = 81, 
                     y = all_res[[3,2]], yend =all_res[[3,2]]), 
                 color = "red") + #common,all
    geom_segment(aes(x = 81, xend = 101, 
                     y = all_res[[4,2]], yend = all_res[[4,2]]), 
                 color = "red") + #large,common,all
    geom_segment(aes(x = 101, xend = 161, 
                     y = all_res[[5,2]], yend = all_res[[5,2]]), 
                 color = "red") + #large,rare,all
  
    geom_segment(aes(x = 40, xend = 51, 
                     y = pos_res[[1,2]], yend = pos_res[[1,2]]), 
                 linetype = 3, color = "black") + #small,rare,pos
    geom_segment(aes(x = 40, xend = 51, 
                     y = neg_res[[1,2]], yend = neg_res[[1,2]]), 
                 linetype = 3, color = "black") + #small,rare,neg
    
    geom_segment(aes(x = 51, xend = 61, 
                     y = pos_res[[2,2]], yend = pos_res[[2,2]]), 
                 linetype = 3, color = "black") + #small,commmon,pos
    geom_segment(aes(x = 51, xend = 61, 
                     y = neg_res[[2,2]], yend = neg_res[[2,2]]), 
                 linetype = 3, color = "black") + #small,common,neg
  
    geom_segment(aes(x =61, xend = 81, 
                     y = pos_res[[3,2]], yend = pos_res[[3,2]]), 
                 linetype = 3, color = "black") + #common,pos
    geom_segment(aes(x =61, xend = 81, 
                     y = neg_res[[3,2]], yend = neg_res[[3,2]]), 
                 linetype = 3, color = "black") + #common,neg
  
    geom_segment(aes(x = 81, xend = 101, 
                     y = pos_res[[4,2]], yend = pos_res[[4,2]]), 
                 linetype = 3, color = "black") + #large,common,post
    geom_segment(aes(x = 81, xend = 101, 
                     y = neg_res[[4,2]], yend = neg_res[[4,2]]), 
                 linetype = 3, color = "black") + #large,common,neg
    geom_segment(aes(x = 101, xend = 161, 
                     y = pos_res[[5,2]], yend = pos_res[[5,2]]), 
                 linetype = 3, color = "black") + #large,rare,post
    geom_segment(aes(x = 101, xend = 161, 
                     y = neg_res[[5,2]], yend = neg_res[[5,2]]), 
                 linetype = 3, color = "black") #large,rare,neg
```
```{r}

```


Playing around with glance, lm. 
```{r}
test <- apatite %>% nest(data = -c(s.gem, gc, np))
test <- apatite %>% nest(data = -s.gem) %>% mutate(fit = map(data, ~lm(s.ft ~ 0 + db.ft, data=.x))) 

lmresults <- test %>% 
  mutate(s = map(fit, summary)) %>% 
  mutate(glance_out = map(s, tidy)) %>%
  select(s.gem, glance_out) %>%
  unnest(glance_out)

```

#Quadrature for volume
```{r}
quad.df.v <- read_excel("/Users/spencerzeigler/Documents/Flowers Lab/Apatite Nano-CT Project_Feb 2019_June 2020/Step 8- Statistics/Linear Reg Results.xlsx", sheet= "vol.reg.master")
quad.df.v <- quad.df.v[c(53:130),]

quad.df.v <- quad.df.v %>%
  select(gem, method.grains, slope, sigma.slope, intercept, sigma.intercept) 
quad.df.v <- quad.df.v[order(quad.df.v$gem),]

        x <- quad.df.v$intercept[19]
        y <- quad.df.v$intercept[20]
  u <- quad.df.v$sigma.intercept[19]
  w <- quad.df.v$sigma.intercept[20]

diff <- x - y
uncert <- sqrt(u^2 + w^2)

if (abs(diff) < abs(uncert)) {
  print("Within 1sigma")
} else {
    print("Not within 1sigma")
}
```

#Quadrature for Ft v2-- using ft.comp
```{r}
quad.df.ft <- read_excel("/Users/spencerzeigler/Documents/Flowers Lab/Apatite Nano-CT Project_Feb 2019_June 2020/Step 8- Statistics/Linear Reg Results.xlsx", sheet= "ft.comp")

quad.df.ft <- quad.df.ft %>%
  select(gem, method.grains, slope, sigma.slope, intercept, sigma.intercept) 
quad.df.ft <- quad.df.ft[order(quad.df.ft$gem),]

        x <- quad.df.ft$slope[7]
        y <- quad.df.ft$slope[8]
  u <- quad.df.ft$sigma.slope[7]
  w <- quad.df.ft$sigma.slope[8]

diff <- x - y
uncert <- sqrt(u^2 + w^2)

if (abs(diff) < abs(uncert)) {
  print("Within 1sigma")
} else {
    print("Not within 1sigma")
}
```


####Dead to me
```{r}
#SLOPE UNCERT, INTERCEPT=0, VOLUME
sigma.slope.v.fixed.incp <- function(linreg, x) {
fit.v <- summary(linreg)
fit.v <- data.frame(fit.v$coefficients)
df <- data.frame(twoD = x$s.v,
                 threeD = x$db.v, 
                 slope = rep(fit.v[1,1], len= nrow(x)))

delta <- nrow(df) * sum(df$twoD^2) - (sum(df$twoD))^2
sigma.y <- sqrt(1/(nrow(df)-2)*sum((df$threeD - 0 - df$twoD*df$slope)^2))
uncert.slope <- sigma.y * sqrt(nrow(df)/delta)
}


#SLOPE UNCERT, INTERCEPT /=/ 0, FT
sigma.slope.ft <- function(linreg, x) {
fit.ft <- summary(linreg)
fit.ft <- data.frame(fit.ft$coefficients)
df <- data.frame(twoD = x$s.ft,
                 threeD = x$db.ft, 
                 intercept = rep(fit.ft[1,1], len=nrow(x)), 
                 slope = rep(fit.ft[2,1], len= nrow(x)))

delta <- nrow(df) * sum(df$twoD^2) - (sum(df$twoD))^2
sigma.y <- sqrt(1/(nrow(df)-2)*sum((df$threeD - df$intercept - df$twoD*df$slope)^2))
uncert.slope <- sigma.y * sqrt(nrow(df)/delta)
}
#INTERCEPT UNCERT, INTERCEPT /=/ 0, FT
sigma.incp.ft <- function(linreg, x) {
fit.ft <- summary(linreg)
fit.ft <- data.frame(fit.ft$coefficients)
df <- data.frame(twoD = x$s.ft,
                 threeD = x$db.ft, 
                 intercept = rep(fit.ft[1,1], len=nrow(x)), 
                 slope = rep(fit.ft[2,1], len= nrow(x)))
delta <- nrow(df) * sum(df$twoD^2) - (sum(df$twoD))^2
sigma.y <- sqrt(1/(nrow(df)-2)*sum((df$threeD - df$intercept - df$twoD*df$slope)^2))
uncert.incept <- sigma.y * sqrt((sum(df$twoD^2))/delta)
}


#SLOPE UNCERT, INTERCEPT /=/ -, VOLUME
sigma.slope.v <- function(linreg, x) {
fit.v <- summary(linreg)
fit.v <- data.frame(fit.v$coefficients)
df <- data.frame(twoD = x$s.v,
                 threeD = x$db.v, 
                 intercept = rep(fit.v[1,1], len=nrow(x)), 
                 slope = rep(fit.v[2,1], len= nrow(x)))

delta <- nrow(df) * sum(df$twoD^2) - (sum(df$twoD))^2
sigma.y <- sqrt(1/(nrow(df)-2)*sum((df$threeD - df$intercept - df$twoD*df$slope)^2))
uncert.slope <- sigma.y * sqrt(nrow(df)/delta)
}
#INTERCEPT UNCERT, INTERCEPT /=/ 0, VOLUME
sigma.incp.v <- function(linreg, x) {
fit.v <- summary(linreg)
fit.v <- data.frame(fit.v$coefficients)
df <- data.frame(twoD = x$s.v,
                 threeD = x$db.v, 
                 intercept = rep(fit.v[1,1], len=nrow(x)), 
                 slope = rep(fit.v[2,1], len= nrow(x)))

delta <- nrow(df) * sum(df$twoD^2) - (sum(df$twoD))^2
sigma.y <- sqrt(1/(nrow(df)-2)*sum((df$threeD - df$intercept - df$twoD*df$slope)^2))
uncert.incept <- sigma.y * sqrt((sum(df$twoD^2))/delta)
}


#Function that produces the normalized residual standard error [must run code chunk that adds residual values to dataframe]
norm.rse <- function(n.resid, n) {
  sqrt((sum((n.resid)^2)/(n-2)))
}

#Function that produces the normalized residual standard error [must run code chunk that adds residual values to dataframe]
norm.rse <- function(n.resid, n) {
  sqrt((sum((n.resid)^2)/(n-2)))
}


```


#Stats Data for A & B- Ft
```{r}
x <- 
robust.ft <- lm(db.ft ~ s.ft, data=x)

#Append Residuals to Dataframes & Calculated Norm. Residual Std Error 
df.ft.resid <- x %>%
  mutate(s.ft.resid = resid(robust.ft)) %>%
  mutate(s.ft.resid.norm = s.ft.resid/db.ft) %>%
  mutate(s.ft.resid.norm.percent = s.ft.resid.norm*100)
n.resid <- df.ft.resid$s.ft.resid.norm
n <- nrow(df.ft.resid)

norm <- norm.rse(n.resid, n)

#For A & B GEM-- formatted for "normal" slope + intercept data
uncert.slope.ft <- sigma.slope.ft(robust.ft, x)
uncert.incep.ft <- sigma.incp.ft(robust.ft, x)


#Create dataframe with values I need
values <- summary(robust.ft)
stats.df.ft <- rbind(slope=values$coefficients[2,1], sigma.slope = uncert.slope.ft, intercept=values$coefficients[1,1], sigma.intercept = uncert.incep.ft, norm.std.error=norm, std.error=values$sigma)
stats.df.ft<- as.data.frame(t(as.matrix(stats.df.ft)))
```

#Stats Data for Fixed Intercept- Ft
```{r}
x <- 
robust.zero.ft <- lm(db.ft ~ 0 + s.ft, data=x)

#Append Residuals to Dataframes & Calculated Norm. Residual Std Error 
y<- resid(robust.zero.ft, na.action = na.exclude)

df.ft.resid <- x %>%
  mutate(s.ft.resid = y) %>%
  mutate(s.ft.resid.norm = s.ft.resid/db.ft) %>%
  mutate(s.ft.resid.norm.percent = s.ft.resid.norm*100)
n.resid <- df.ft.resid$s.ft.resid.norm
n <- nrow(df.ft.resid)

norm <- norm.rse(n.resid, n)

#Uncertainty in slope and intercept
uncert.slope.ft <- slope.uncertainty.ft(robust.zero.ft, x)

#Create dataframe with values I need
values <- summary(robust.zero.ft)
stats.df.ft <- rbind(slope=values$coefficients[1,1], sigma.slope = uncert.slope.ft, intercept=0, sigma.intercept = 0, norm.std.error=norm, std.error=values$sigma)
stats.df.ft <- as.data.frame(t(as.matrix(stats.df.ft)))
```

#Stats Data for A & B- Volume
```{r}
x <- df.ab
robust.v <- lm(db.v ~ s.v, data=x)

#Append Residuals to Dataframes & Calculated Norm. Residual Std Error 
df.v.resid <- x %>%
  mutate(s.v.resid = resid(robust.v)) %>%
  mutate(s.v.resid.norm = s.v.resid/db.v) %>%
  mutate(s.v.resid.norm.percent = s.v.resid.norm *100) 

n.resid <- df.v.resid$s.v.resid.norm
n <- nrow(df.v.resid)

norm <- norm.rse(n.resid, n)

#For A & B GEM-- formatted for "normal" slope + intercept data
uncert.slope.v <- sigma.slope.v(robust.v, x)
uncert.incep.v <- sigma.incp.v(robust.v, x)

#Create dataframe with values I need
values <- summary(robust.v)
stats.df.v <- rbind(slope=values$coefficients[2,1], sigma.slope = uncert.slope.v, intercept=values$coefficients[1,1], sigma.intercept = uncert.incep.v, norm.std.error=norm, std.error=values$sigma)
stats.df.v<- as.data.frame(t(as.matrix(stats.df.v)))
```

#Stats Data for C - Volume
```{r}
x <- df.c3
robust.zero.v <- lm(db.v ~ 0 + s.v, data=x)

#Append Residuals to Dataframes & Calculated Norm. Residual Std Error 
df.v.resid <- x %>%
  mutate(s.v.resid = resid(robust.zero.v)) %>%
  mutate(s.v.resid.norm = s.v.resid/db.v) %>%
  mutate(s.v.resid.norm.percent = s.v.resid.norm *100) 

n.resid <- df.v.resid$s.v.resid.norm
n <- nrow(df.v.resid)

norm <- norm.rse(n.resid, n)

#For A & B GEM-- formatted for "normal" slope + intercept data
uncert.slope.v <- sigma.slope.v.fixed.incp(robust.zero.v, x)

#Create dataframe with values I need
values <- summary(robust.zero.v)
stats.df.v <- rbind(slope=values$coefficients[1,1], sigma.slope = uncert.slope.v, intercept=0, sigma.intercept = 0, norm.std.error=norm, std.error=values$sigma)
stats.df.v<- as.data.frame(t(as.matrix(stats.df.v)))
```


Nested equivilent of tidymodels bootstrap
```{r}
sample_df_nested <- common_apatite %>% 
      select(sample, s.gem, s.ft,  db.ft) %>% 
      rename(twoD = s.ft,  threeD = db.ft) %>%
      nest(data= -s.gem)
  
  set.seed(123)
  #Perform bootstrap 
  nested_boot <- bootstraps(sample_df_nested,
                            times = 1000,
                            apparent = TRUE)
  nested_split <- nested_boot$splits
  
  #Run linear regression on each bootstrap
  for (i in 1:1001) {r
    sample_models_nested <- map(nested_split[[i]]$data[[2]], ~ lm(twoD ~ 0 + threeD, data = .))
  }

#Get coefficients
sample_coefs_nested <- map(sample_models_nested, ~ tidy(.x))
sample_coefs_nested <- do.call(rbind.data.frame, sample_coefs_nested)
sample_coefs_nested <- cbind(c("A1", "A2", "A3", "B1", "B2", "B3", "C1", "C2", "C3"), sample_coefs_nested)%>% rename(gem =  'c("A1", "A2", "A3", "B1", "B2", "B3", "C1", "C2", "C3")')
```

Unnested equivilent of tidymodels bootstrap-- to play around with.
```{r}
sample_df <- apatite %>% 
      select(sample, s.gem, s.ft,  db.ft) %>% 
      rename(twoD = s.ft,  threeD = db.ft) 
  
  set.seed(123)
  #Perform bootstrap 
  sample_boot <- bootstraps(sample_df,
                            times = 1000,
                            apparent = F)
  
  hist(apatite$s.ft)
  hist(sample_boot$splits[[100]][[1]][[3]])
  hist(apatite$db.ft)
  
  hist(sample_boot$splits[[100]][[1]][[4]])

  bootstraps(mtcars, times = 2)
  
  
  #Run linear regression on each bootstrap
  sample_models <- sample_boot %>% 
    mutate(model = map(splits, ~ lm(twoD ~ 0 + threeD,
                                    data = .) ),
           coef_inf = map(model, tidy))
  
  #Get coefficients
  sample_coefs <- sample_models %>% 
    unnest(coef_inf)
  
  #Get confidence interval 
  percentile_intervals <- int_pctl(sample_models,
                                   coef_inf)
  
  #Store results
  results <<- as.data.frame(cbind(percentile_intervals$.estimate, sd(sample_coefs$estimate),mean(sample_coefs$std.error), (1/percentile_intervals$.estimate))) %>%
    rename(slope = V1, sd = V2, std.error = V3, plot.slope= V4 )
  
  print(results)
```

```{r}
manualboot_subset <- sample(common_apatite$s.ft, 100, replace = F) 
hist(manualboot)
hist(common_apatite$s.ft)
hist(manualboot_subset)

manualboot_subset <- sample(common_apatite$s.ft, 100, replace = F) 

```



Dead to me round 2:
################################################################################################


#Uncertainty Calculations
```{r}
apatite <- apatite %>%
  mutate(ri.cat = ifelse(ri == "3", "3", "12"))

df <- apatite %>%
  select(sample, gem.geo, ri, ri.cat, size.cat, s.ft, db.ft, s.v, db.v) %>%
  filter(gem.geo == "C") %>%
  nest_by(size.cat, ri.cat) 

models <- df %>%
  mutate(model = list(lm(s.v ~ 0 + db.v, data = data)))

#create db which are lists of 3d values the same length of each of the model results (residuals): this is for calculating the percent difference 
db <- vector("list", nrow(df))

for (i in 1:nrow(df)) {
  db[[i]] <- unlist(df[[3]][[i]]$db.v)
}

#extract each residual result
sample_residuals <- vector("list", nrow(df))
for (i in 1:nrow(df)) {
  sample_residuals[[i]] <- unlist(models$model[[i]][[2]])
}

#get final results 
results <-  matrix(nrow = nrow(df), ncol = 2)
median <- vector("numeric", nrow(df))
std.dev <- vector("numeric", nrow(df))
n <- vector("numeric", nrow(df))

for (i in 1:nrow(df)) {
  x <- sample_residuals[[i]]
  y <- db[[i]]
  
  percent.diff  <-(x/y)*100
  median[i] <- median(percent.diff)
  std.dev[i] <-  sd(percent.diff)
  n[i] <- length(x)
  
  results <- cbind(median, std.dev, n)
}
```

Creating uncertainty dataframes: 
### Only bit that needs to change is x, z, y. Need to change this before plotting.
```{r}
x <- c_all_residuals_ft[,1001] #extract residuals calculated from observed data
z <- c_all$db.ft #extract 'real' value to calculate % difference
y <- c_all #store dataframe that corresponds to calculated residuals

#Combine all columns from above & parameters we care about (ie. size bin and name)
original_residuals <- bind_cols(og.residuals = x,
                                percent.diff = (x/z)*100,
                                size.name = y$size.name, 
                                #size.bin = y$size.bin, 
                                size.cat = y$size.cat,
                                ri = y$ri) 
#Store just the percent difference value for plotting later
percent.diff <- original_residuals$percent.diff

#Format original residuals dataframe 
original_residuals <- pivot_longer(original_residuals, cols = 3:5, names_to = "category") 
#Set as factors to force output tables into the right order 
original_residuals$value <- factor(original_residuals$value, levels = c("rare- small", "common", "rare- large", "Small & Rare", "Small & Common", "Typical & Common", "Large & Common", "Large & Rare", "1", "2", "3"))

all_res <- original_residuals %>% 
  mutate(sign = "total") %>%
  group_by(value, sign) %>%
  summarise(median_res = median(percent.diff), sd_res = sd(percent.diff))

sign_res <- original_residuals %>%
  mutate(sign = ifelse(percent.diff > 0, "positive", "negative")) %>%
  group_by(value, sign) %>% 
  summarise(median_res = median(percent.diff), sd_res = sd(percent.diff))

res_plotting <- bind_rows(all_res, sign_res) 
res_results <- res_plotting %>%
  pivot_wider(values_from = 3:4, names_from = sign)
```


# t-test to assess if slopes are statistically the same or not
```{r}
ttest_compare(b_all_slopes_volume, c_all_slopes_volume)

t.test(b_slopes_volume, a_slopes_volume, conf.level = 0.6827)
x <- sample(ab_slopes_volume, 100)
y <- sample(a_slopes_volume, 100)
t.test(x,y)
#if t-test p value is < 2.2e-16, result will be a p-value of 0
#https://github.com/tidymodels/broom/issues/227

```


```{r}
linreg <- lm(s.ft ~ 0 + db.ft, gca)

std.err <- sqrt(sum((gca$s.ft - linreg$fitted.values)^2) / (nrow(gca) - 2))
sb <- std.err / sqrt(sum((gca$db.ft - mean(gca$db.ft))^2))

#This gives me the same uncertainty as the excel LINEST and for Taylor 
#https://sites.chem.utoronto.ca/chemistry/coursenotes/analsci/stats/ErrRegr.html
```


```{r}
results.a <- slope.uncertainty(gca, "ft")
results.b <- slope.uncertainty(gcb, "ft")
results.c <- slope.uncertainty(gcc, "ft")

t.test(results.a$slope, results.b$slope)

# m1, m2: the sample means
# s1, s2: the sample standard deviations
# n1, n2: the same sizes
# m0: the null value for the difference in means to be tested for. Default is 0. 
# equal.variance: whether or not to assume equal variance. Default is FALSE. 
t.test2 <- function(m1,m2,s1,s2,n1,n2,m0=0,equal.variance=FALSE)
{
    if( equal.variance==FALSE ) 
    {
        se <- sqrt( (s1^2/n1) + (s2^2/n2) )
        # welch-satterthwaite df
        df <- ( (s1^2/n1 + s2^2/n2)^2 )/( (s1^2/n1)^2/(n1-1) + (s2^2/n2)^2/(n2-1) )
    } else
    {
        # pooled standard deviation, scaled by the sample sizes
        se <- sqrt( (1/n1 + 1/n2) * ((n1-1)*s1^2 + (n2-1)*s2^2)/(n1+n2-2) ) 
        df <- n1+n2-2
    }      
    t <- (m1-m2-m0)/se 
    dat <- c(m1-m2, se, t, 2*pt(-abs(t),df))    
    names(dat) <- c("Difference of means", "Std Error", "t", "p-value")
    return(dat) 
}

t.test2(results.a$slope, results.b$slope, results.a$sigma.slope, results.b$sigma.slope, length(gca$s.ft), length(gcb$s.ft))

t.test2(mean(a_slopes_ft), mean(b_slopes_ft), sd(a_slopes_ft), sd(b_slopes_ft), 1001, 1001)
#A and B are equal

t.test2(results.a$slope, results.c$slope, results.a$sigma.slope, results.c$sigma.slope, length(gca$s.ft), length(gcc$s.ft))

#A and C are different (reject the null)

t.test2(results.b$slope, results.c$slope, results.b$sigma.slope, results.c$sigma.slope, length(gcb$s.ft), length(gcc$s.ft))

#B and C are different
```



Using bootstrap code to get vectors of slopes to perform t-tests on:
```{r}
    sample_df <- gcc %>% select(sample, s.ft,  db.ft) %>% rename(twoD = s.ft,  threeD = db.ft)
  
  # Set set.seed a starting number to generate a sequence of random numbers so that we can get reproducible results
  set.seed(123)
  #Perform bootstrap 
  sample_boot <- bootstraps(sample_df,
                            times = 1000,
                            apparent = TRUE)
  
  #Run linear regression on each bootstrap
  sample_models <- sample_boot %>% 
    mutate(model = map(splits, ~ lm(twoD ~ 0 + threeD,
                                    data = .) ),
           coef_inf = map(model, tidy))
  #Get coefficients
  sample_coefs <- sample_models %>% 
    unnest(coef_inf)
  

  
  #Get confidence interval 
  percentile_intervals <- int_pctl(sample_models,
                                   coef_inf)
  
  #Store results
  results <<- as.data.frame(cbind(percentile_intervals$.estimate, sd(sample_coefs$estimate),mean(sample_coefs$std.error), (1/percentile_intervals$.estimate))) %>%
    rename(slope = V1, sd = V2, std.error = V3, plot.slope= V4)
  
```

```{r}
lower.ci <- percentile_intervals$.estimate - percentile_intervals$.lower
upper.ci <- percentile_intervals$.upper - percentile_intervals$.estimate 
average.ci <- (lower.ci + upper.ci)/2
```


#Using t test to see if slope values overlap within 1sigma. Same as quadrature. 
```{r}
#Stick this into the bootstrap.linreg code-- unnested. 
  slopes.gcb <- sample_coefs$estimate
  slopes.gca <- sample_coefs$estimate
  slopes.gcc <- sample_coefs$estimate

#then do t-tests if you hate urself but you don't need to the results are the same as quadrature. 

t.test(ab_slopes_ft, a_slopes_ft)

gca.2.5 <- quantile(slopes.gca, .025)
gca.97.5 <- quantile(slopes.gca,.975)

gcc.2.5 <- quantile(slopes.gcc, .025)
gcc.97.5 <-  quantile(slopes.gcc, .975)

gcb.2.5 <- quantile(slopes.gcb, .025)
gcb.97.5 <-  quantile(slopes.gcb, .975)

```

Average % error
```{r}
percent.diff <- function(df) {
   ftd <- round(mean(abs(df$s.ft - df$db.ft)/((df$s.ft + df$db.ft)/2) * 100),2)
   fts <- round(2*sd(abs(df$s.ft - df$db.ft)/((df$s.ft + df$db.ft)/2) * 100),2)
 
    vd <- round(mean(abs(df$s.v - df$db.v)/((df$s.v + df$db.v)/2) * 100),2)
    vs <- round(2*sd(abs(df$s.v - df$db.v)/((df$s.v + df$db.v)/2) * 100),2)
  
    sad <- round(mean(abs(df$s.sa - df$db.sa)/((df$s.sa + df$db.sa)/2) * 100), 2)
    sas <- round(2*sd(abs(df$s.sa - df$db.sa)/((df$s.sa + df$db.sa)/2) * 100),2)
    esrd <- round(mean(abs(df$s.esr.ft - df$db.esr.ft)/((df$s.esr.ft + df$db.esr.ft)/2) * 100), 2)
    esrs <- round(2*sd(abs(df$s.esr.ft - df$db.esr.ft)/((df$s.esr.ft + df$db.esr.ft)/2) * 100),2)
  
    abs.diff <- c(ftd, vd, sad, esrd)
    twosigma <- c(fts, vs, sas, esrs)
    
return(data.frame(abs.diff, twosigma, row.names = c("ft", "vol", "sa", "esr")))
}

ri12 <- apatite %>% filter(ri == "1" | ri == "2")

percent.diff(apatite)
percent.diff(gcc)
percent.diff(ab)
percent.diff(ri12)
percent.diff(ri3)
```

#Sampling a subset of the data (without replacement)
```{r}
#Sample size should be ~10% of population 

unique2d <- matrix(nrow = 20, ncol = 1000)
unique3d <- matrix(nrow = 20, ncol = 1000)
uniqueslopes <- list()


for (i in 1:1000) {
  unique2d[,i] <- sample(common_apatite$s.ft, size=20, replace = F)
  unique3d[,i] <- sample(common_apatite$db.ft, size=20, replace = F)
  uniqueslopes[i] <- summary(lm(unique2d[,i] ~ 0 + unique3d[,i]))$coefficients[[1]]
}

uniqueslopes <- unlist(uniqueslopes) 
uniqueslopes <- as.data.frame(uniqueslopes)

unique2d <- as.data.frame(unique2d) %>%
  rename(simulated1 = V1, simulated2 = V2, simulated3 = V3, simulated4= V4)
unique2d <- unique2d %>% pivot_longer(cols = 1:4)

ggplot() + 
  geom_histogram(uniqueslopes, mapping = aes(x = uniqueslopes), fill = "white", color = "black") +
  labs(title = "Slopes calculated from 1000 samples of n= 20 (without replacement)", x = "Slopes") +
  geom_vline(xintercept = mean(uniqueslopes$uniqueslopes), color = "blue", size =1.5) +
  annotate("text", x = 1.045, y = 95, label = glue("mean = {round(mean(uniqueslopes$uniqueslopes),3)}"), size = 5)

sd(uniqueslopes$uniqueslopes)

ggplot() + 
  geom_histogram(unique2d, mapping=aes(x=value)) +
  facet_wrap(~name) +
  xlab("2D Ft") 

ggplot() + 
  geom_histogram(common_apatite, mapping=aes(x=s.ft)) 
```

#Sampling with replacement
```{r}
replaced2d <- matrix(nrow = 20, ncol = 1000)
replaced3d <- matrix(nrow = 20, ncol = 1000)
replacedslopes_ab <- list()
replacedslopes_c <- list()
for (i in 1:1000) {
  replaced2d[,i] <- sample(ab$s.v, size=20, replace = T)
  replaced3d[,i] <- sample(ab$db.v, size=20, replace = T)
  replacedslopes_ab[i] <- summary(lm(replaced2d[,i] ~ 0 + replaced3d[,i]))$coefficients[[1]]
}
replacedslopes_ab <- unlist(replacedslopes_ab)
replacedslopes_c <- unlist(replacedslopes_c)
replacedslopes_ <- as.data.frame(replacedslopes)

replaced2d <- as.data.frame(replaced2d) %>%
  rename(simulated1 = V1, simulated2 = V2, simulated3 = V3, simulated4= V4)
replaced2d <- replaced2d %>% pivot_longer(cols = 1:4)

ggplot() + 
  geom_histogram(replacedslopes, mapping = aes(x = replacedslopes), fill = "white", color = "black") +
  labs(title = "Slopes calculated from 1000 samples of n= 200 (with replacement)", x = "Slopes") +
  geom_vline(xintercept = mean(replacedslopes$replacedslopes), color = "red", size =1.5) +
  annotate("text", x = 1.035, y = 90, label = glue("mean = {round(mean(replacedslopes$replacedslopes),3)}"), size = 5)

sd(replacedslopes$replacedslopes)


mean(replacedslopes$replacedslopes)
ggplot() + 
  geom_histogram(replaced2d, mapping=aes(x=value)) +
  facet_wrap(~name) + xlab("2D Ft")


ggplot() + 
  geom_histogram(replaced2d, mapping=aes(x= replaced2d))




```

##Resources:

* [Bootstrapping Code](https://towardsdatascience.com/bootstrap-sampling-in-r-a7bc9d3ca14a)
* [Confidence Intervals vs Std Deviation](https://stats.stackexchange.com/questions/151541/confidence-intervals-vs-standard-deviation/377634#:~:text=standard%20deviation,-confidence%2Dinterval%20standard&text=The%2095%25%20confidence%20interval%20gives,a%20range%20of%20~95%25.)
* [Overlapping Confidence Intervals](https://towardsdatascience.com/tutorial-for-using-confidence-intervals-bootstrapping-860ba716aef3)


### Taylor Method

#Quadrature
```{r}
slope.uncertainty(c, "volume")

#read in spreadsheet of linear regression values
quad <- read_excel("./Linear Reg Results.xlsx", sheet="comp")

#function
error.propagation(quad, "common.only", "volume", "B", "C")
```

