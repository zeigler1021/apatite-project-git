sd(z)
mean(z)
mean(y)
sd(y)
sd(z)
mean(z)
sd(z)
sum(x - mean(x))^2
(x - mean(x))^2 * (999-1)
sum((x - mean(x))^2 * (999-1))
?pexp
pexp(1, 5)
sum(dexp(1,5))
1-p(exp(1,5))
1-pexp(1,5))
1-pexp(1,5)
1-e^(-5*1)
1-exp^(-5*1)
1-exp(-5*1)
dexp(1,5)
sum(dexp(1,5))
x <- 2:9
log10(x/(x-1))
sum(log10(x/(x-1)))
.5^4
.5^4/4
.0625/4
.5^2
-(4/3)*(.015625-0.25)
1-0.3125
1/100
(0.5*0.01) + (0.4 * (1-0.01))
(0.5*0.01)/0.401
x <- runif(10, 0, 100)
x <- rborm(10, 0, 100)
x <- rnorm(10, 0, 100)
sum(x - mean(x))
sum((1:10 - 1) * mean(x))
sum(x) - sum(x/10)
sum(x) - sum(x)
sum(10 - 1) * mean(x))
sum(10 - 1 * mean(x))
(9 * mean(x))
sum(x - mean(x))
#LHS
sum(x - (sum(x)/10))
sum(x - mean(x))
x <- rnorm(10, 0, 100)
#RHS
(9 * mean(x))
#LHS
sum(x - (sum(x)/10))
sum(x) - sum(x/10)
#LHS
sum(x)-mean(x)
sum(x) - sum(sum(x/10))
sum(x) - sum(sum(x)/10)
x <- rnorm(10000, -20, 20)
y <- x - mean(x)
z <- y / sd(x)
v <- x/sd(x)
df <- cbind(x, y, z, v)
View(df)
df <- as.data.frame(df)
df <- pivot_longer(1:4)
df <- pivot_longer(df, 1:4)
View(df)
ggplot(df, (x= values)) +
geom_histogram
ggplot(df, (x= values)) +
geom_histogram()
ggplot(df, (x= value)) +
geom_histogram()
ggplot(df, (x= value)) +
geom_histogram()
df <- pivot_longer(df, 1:4) %>%
rename(number = value)
df <- rename(df, number = value)
ggplot(df, (x= number)) +
geom_histogram()
ggplot(df, aes(x= number)) +
geom_histogram()
View(df)
ggplot(df, aes(x= number, color = name)) +
geom_histogram()
ggplot(df, aes(x= number, fill = name)) +
geom_histogram()
ggplot(df, aes(x= number, fill = name), alpha = .7) +
geom_histogram()
ggplot(df, aes(x= number, fill = name)) +
geom_histogram(alpha = .7)
x <- rnorm(10000, 0, 20)
y <- x - mean(x)
z <- y / sd(x)
v <- x/sd(x)
df <- cbind(x, y, z, v)
df <- as.data.frame(df)
df <- pivot_longer(df, 1:4)
df <- rename(df, number = value)
ggplot(df, aes(x= number, fill = name)) +
geom_histogram(alpha = .7)
x <- rnorm(1000, 0, 20)
y <- x - mean(x)
z <- y / sd(x)
v <- x/sd(x)
df <- cbind(x, y, z, v)
df <- as.data.frame(df)
df <- pivot_longer(df, 1:4)
df <- rename(df, number = value)
ggplot(df, aes(x= number, fill = name)) +
geom_histogram(alpha = .7)
View(df)
x <- rnorm(1000, 1, 20)
y <- x - mean(x)
z <- y / sd(x)
v <- x/sd(x)
df <- cbind(x, y, z, v)
df <- as.data.frame(df)
df <- pivot_longer(df, 1:4)
df <- rename(df, number = value)
ggplot(df, aes(x= number, fill = name)) +
geom_histogram(alpha = .7)
x <- rnorm(1000, 1, 20)
y <- x - mean(x)
z <- y / sd(x)
v <- x/sd(x)
df <- cbind(x, y, z, v)
mean(df$x)
View(df)
mean(x)
mean(y)
x <- rnorm(1000, 10,3)
y <- x - mean(x)
z <- y / sd(x)
v <- x/sd(x)
df <- cbind(x, y, z, v)
df <- as.data.frame(df)
df <- pivot_longer(df, 1:4)
df <- rename(df, number = value)
ggplot(df, aes(x= number, fill = name)) +
geom_histogram(alpha = .7)
x <- rnorm(1000, 10, 3)
mean(x)
y <- x - mean(x)
mean(y)
sd(y)
z <- y/sd(x)
sd(z)
mean(z)
# Chunk 1: setup
#for stats
options(java.parameters = "-Xmx8000m") #to prevent Java heap space error. set to full RAM of this computer (8gB)
#https://stackoverflow.com/questions/21937640/handling-java-lang-outofmemoryerror-when-writing-to-excel-from-r
library(rJava)
library(MASS)
library(performance) #check model
library(tidymodels)
library(tictoc) #check how long model takes to run
#tidyverse
library(tidyverse) #purr, dplyr, tidyr, readr, readxl, tibble, stringr, forcats, ggplot2
library(broom)
library(scales)
library(readxl)
library(glue)
library(tibble)
#for viz
library(plotly)
library(patchwork)
library(RColorBrewer)
library(colorspace)
library(jcolors)
library(viridis)
library(ggsci)
library(ggthemes)
library(DescTools)
library(dichromat)
#for knitting
library(knitr)
library(tinytex)
library(latex2exp)
#library(xlsx)
#library(datapaste)
par(mfrow=c(1, 1)) #how to arrange plots, 1 per row, 1 per column
#Theme options
theme_set(theme_light())
theme_update(plot.title = element_text(hjust = 0.5)) #adjusts theme so that all titles are centered
theme_update(plot.subtitle= element_text(hjust = 0.5)) #adjusts subtitle so they are all centered
options(scipen = 10000000) #prints numbers instead of scientific notation
# Chunk 2
qual_color_random <- c("#322288", "#aa4499", "#44aa99", "#671000", "#989934", "#6599cc", "#aa4466", "#ddcc77", "#000000")
cb <- c("#595959", "#5f9ed1", "#c85200")
cb2 <- c("#f06400", "#949494", "#008CF0")
tf_color <- c("#ed6a5e", "#9ebc9e", "#553e4e")
# Chunk 3
apatite <- read_excel("./Data Comps_Final.xlsx", sheet="Data Comps")
apatite <- apatite[-c(42, 166, 217, 218, 244),] #delete termination end grains
as_tibble(apatite)
# Chunk 4
apatite$size.bin <- factor(apatite$size.bin, levels = c("40-50", "51-60", "61-70", "71-80", "81-90", "91-100", "101-110", "111-120", "121-130", "131-140", "141-150", "151-160", "161-170"))
apatite$gem <- factor(apatite$gem, levels = c("A1", "A2", "B1", "B2", "C1", "C2"))
apatite$gc <- factor(apatite$gc, levels = c("A", "B", "C"))
apatite$ri <- factor(apatite$ri, levels = c("1", "2"))
apatite$size.name <- factor(apatite$size.name, levels=c("Small & Rare","Small & Common","Typical & Common", "Large & Common", "Large & Rare"))
apatite$size.cat <- factor(apatite$size.cat, levels = c("rare- small", "common",  "rare- large"))
groupings <- as.vector(c("A", "A1", "A2", "B", "B1", "B2", "C", "C1", "C2", "hexagonal", "ellipsoid", "1", "2", "term0", "term1", "term2", "rare- small", "common", "rare- large"), mode = "character")
# Chunk 5
# #get vector of sheet names
# sheet_names <- excel_sheets("./Regression Results_Final.xlsx")
# #import all sheets into a list
# linreg_results <- lapply(sheet_names, function(x) read_excel(path = "./Regression Results_Final.xlsx", sheet = x))
# #export each element of list as a dataframe
# for (i in 1:20) {
#   assign(paste(sheet_names[[i]]), linreg_results[[i]])
# }
# Chunk 6
#Dataframe by Roughness Index
ri1 <- apatite %>% filter(ri=="1")
ri2 <- apatite %>% filter(ri=="2")
#Dataframe by Geometric Classification
a <- apatite %>% filter(gc=="A")
b <- apatite %>% filter(gc=="B")
c <- apatite %>% filter(gc=="C")
#Create Dataframes split by both geometry and roughness
a1 <- apatite %>% filter(gem == "A1")
a2 <- apatite %>% filter(gem == "A2")
b1 <- apatite %>% filter(gem == "B1")
b2 <- apatite %>% filter(gem == "B2")
c1 <- apatite %>% filter(gem == "C1")
c2 <- apatite %>% filter(gem == "C2")
#Make dataframes based on geometry
hex <- apatite %>% filter(geo == "hexagonal")
ellip <- apatite %>% filter(geo == "ellipsoid")
hex <- apatite %>% filter(gc == "A" | gc == "B")
ellip <- apatite %>% filter(gc == "C")
#Make dataframe based on size
rare_small <- apatite %>% filter(size.cat == "rare- small")
common <- apatite %>% filter(size.cat == "common")
rare_large <- apatite %>% filter(size.cat == "rare- large")
# Chunk 7
source("./Functions/function_error_propagation.R")
source("./Functions/function_bootstrapped_slopes.R")
#source("function_linreg_slope_uncertainty.R")
source("./Functions/function_model_diagnostics.R")
#source("function_ttest_compare.R")
source("./Functions/function_bootstrap_linreg_nested.R")
source("./Functions/function_taylor_uncertainties_nested.R")
source("./Functions/function_taylor_uncertainties_nested_notfixed.R")
source("./Functions/function_bootstrap_linreg_nested_notfixed.R")
source("./Functions/function_manual_pvalue.R")
source("./Functions/function_taylor_overlap.R")
source("./Functions/function_residual_uncertainty.R")
# Chunk 8
#source("function_error_lines.R")
#source("function_plot_results.R")
sample_df <- ellip %>%
filter(np.ognp == "term0") %>%
select(sample, gem, s.ft.ognp,  db.ft) %>%
rename(twoD = s.ft, threeD = db.ft)
sample_df <- ellip %>%
filter(np.ognp == "term0") %>%
select(sample, gem, s.ft.ognp,  db.ft) %>%
rename(twoD = s.ft.ognp, threeD = db.ft)
set.seed(123)
#Perform bootstrap
sample_boot <- bootstraps(sample_df,
times = 1000,
apparent = TRUE)
#Run linear regression on each bootstrap
sample_models <- sample_boot %>%
mutate(model = map(splits, ~ lm(twoD ~ 0 + threeD,
data = .) ),
coef_inf = map(model, tidy))
#Get coefficients
sample_coefs <- sample_models %>%
unnest(coef_inf)
#Get confidence interval
percentile_intervals <- int_pctl(sample_models,
coef_inf)
#Store results
results_boot_ellip_0_ft <- as.data.frame(cbind(mean(sample_coefs$estimate), (1/percentile_intervals$.estimate))) %>%
rename(slope = V1, plot.slope= V2)
slopes_boot_ellip_0_ft <- sample_coefs$estimate
print(results_boot_ellip_0_ft)
slope <- mean(slopes_boot_eliip_0_ft)
slope <- mean(slopes_boot_ellip_0_ft)
sample_df <- cbind(select(ellip, sample, s.ft.ognp, db.ft), slope)
percent_diff <- ((sample_df$s.ft.ognp - (sample_df$slope * sample_df$db.ft)) / sample_df$s.ft.ognp) * 100
uncert <- sd(percent_diff) #/ sqrt(length(filter(hex, size.cat == "common")))
sample_df <- ellip %>%
filter(np.ognp == "term0") %>%
select(sample, gem, s.v.ognp,  db.v) %>%
rename(twoD = s.v.ognp, threeD = db.v)
set.seed(123)
#Perform bootstrap
sample_boot <- bootstraps(sample_df,
times = 1000,
apparent = TRUE)
#Run linear regression on each bootstrap
sample_models <- sample_boot %>%
mutate(model = map(splits, ~ lm(twoD ~ 0 + threeD,
data = .) ),
coef_inf = map(model, tidy))
#Get coefficients
sample_coefs <- sample_models %>%
unnest(coef_inf)
#Get confidence interval
percentile_intervals <- int_pctl(sample_models,
coef_inf)
#Store results
results_boot_ellip_0_v <- as.data.frame(cbind(mean(sample_coefs$estimate), (1/percentile_intervals$.estimate))) %>%
rename(slope = V1, plot.slope= V2)
slopes_boot_ellip_0_v <- sample_coefs$estimate
print(results_boot_ellip_0_v)
#manual p value
```{r}
pvalue <- sum(slopes_boot_ognp_v < slopes_boot_v)/1001
```
slope <- mean(slopes_boot_ellip_0_v)
sample_df <- cbind(select(ellip, sample, s.v.ognp, db.v), slope)
percent_diff <- ((sample_df$s.v.ognp - (sample_df$slope * sample_df$db.v)) / sample_df$s.v.ognp) * 100
uncert <- sd(percent_diff) #/ sqrt(length(filter(hex, size.cat == "common")))
sample_df <- ellip %>%
filter(np.ognp == "term1") %>%
select(sample, gem, s.v.ognp,  db.v) %>%
rename(twoD = s.v.ognp, threeD = db.v)
set.seed(123)
#Perform bootstrap
sample_boot <- bootstraps(sample_df,
times = 1000,
apparent = TRUE)
#Run linear regression on each bootstrap
sample_models <- sample_boot %>%
mutate(model = map(splits, ~ lm(twoD ~ 0 + threeD,
data = .) ),
coef_inf = map(model, tidy))
#Get coefficients
sample_coefs <- sample_models %>%
unnest(coef_inf)
#Get confidence interval
percentile_intervals <- int_pctl(sample_models,
coef_inf)
#Store results
results_boot_ellip_0_v <- as.data.frame(cbind(mean(sample_coefs$estimate), (1/percentile_intervals$.estimate))) %>%
rename(slope = V1, plot.slope= V2)
#Store results
results_boot_ellip_1_v <- as.data.frame(cbind(mean(sample_coefs$estimate), (1/percentile_intervals$.estimate))) %>%
rename(slope = V1, plot.slope= V2)
slopes_boot_ellip_1_v <- sample_coefs$estimate
print(results_boot_ellip_1_v)
slope <- mean(slopes_boot_ellip_1_v)
sample_df <- cbind(select(ellip, sample, s.v.ognp, db.v), slope)
percent_diff <- ((sample_df$s.v.ognp - (sample_df$slope * sample_df$db.v)) / sample_df$s.v.ognp) * 100
uncert <- sd(percent_diff) #/ sqrt(length(filter(hex, size.cat == "common")))
sample_df <- ellip %>%
filter(np.ognp == "term1") %>%
select(sample, gem, s.ft.ognp,  db.ft) %>%
rename(twoD = s.ft.ognp, threeD = db.ft)
set.seed(123)
#Perform bootstrap
sample_boot <- bootstraps(sample_df,
times = 1000,
apparent = TRUE)
#Run linear regression on each bootstrap
sample_models <- sample_boot %>%
mutate(model = map(splits, ~ lm(twoD ~ 0 + threeD,
data = .) ),
coef_inf = map(model, tidy))
#Get coefficients
sample_coefs <- sample_models %>%
unnest(coef_inf)
#Get confidence interval
percentile_intervals <- int_pctl(sample_models,
coef_inf)
#Store results
results_boot_ellip_1_ft <- as.data.frame(cbind(mean(sample_coefs$estimate), (1/percentile_intervals$.estimate))) %>%
rename(slope = V1, plot.slope= V2)
slopes_boot_ellip_1_ft <- sample_coefs$estimate
print(results_boot_ellip_1_ft)
slope <- mean(slopes_boot_ellip_1_ft)
sample_df <- cbind(select(ellip, sample, s.ft.ognp, db.ft), slope)
percent_diff <- ((sample_df$s.ft.ognp - (sample_df$slope * sample_df$db.ft)) / sample_df$s.ft.ognp) * 100
uncert <- sd(percent_diff) #/ sqrt(length(filter(hex, size.cat == "common")))
sample_df <- hex %>%
#filter(np.ognp == "term1") %>%
select(sample, gem, s.ft,  db.ft) %>%
rename(twoD = s.ft, threeD = db.ft)
set.seed(123)
#Perform bootstrap
sample_boot <- bootstraps(sample_df,
times = 1000,
apparent = TRUE)
#Run linear regression on each bootstrap
sample_models <- sample_boot %>%
mutate(model = map(splits, ~ lm(twoD ~ 0 + threeD,
data = .) ),
coef_inf = map(model, tidy))
#Get coefficients
sample_coefs <- sample_models %>%
unnest(coef_inf)
#Get confidence interval
percentile_intervals <- int_pctl(sample_models,
coef_inf)
#Store results
results_boot_ft <- as.data.frame(cbind(mean(sample_coefs$estimate), (1/percentile_intervals$.estimate))) %>%
rename(slope = V1, plot.slope= V2)
slopes_boot_ft <- sample_coefs$estimate
print(results_boot_ft)
slope <- mean(slopes_boot_ft)
sample_df <- cbind(select(hex, sample, s.ft, db.ft), slope)
residual <- sample_df$s.ft - (sample_df$slope * sample_df$db.ft)
uncert.resid <- sd(residual)
sample_df <- cbind(select(hex, sample, s.ft, db.ft, size.cat), slope)  %>%
filter(size.cat == "small- rare")
sample_df <- cbind(select(hex, sample, s.ft, db.ft, size.cat), slope)  %>%
filter(size.cat == "rare- small")
residual <- sample_df$s.ft - (sample_df$slope * sample_df$db.ft)
uncert.resid <- sd(residual)
uncert.resid <- sd(residual) * 100
uncert.resid <- sd(residual)
qt(0.975, df = 15) * sd(rare_small)/sqrt(16)
qt(0.975, df = 15) * uncert.resid/sqrt(16)
qt(0.975, df = 15) * uncert.resid/sqrt(16) * 100
apatite %>%
filter(s.v.ognp == "0") %>%
ggplot(aes(x = s.v., y = db.v)) +
geom_point()
apatite %>%
filter(s.v.ognp == "0") %>%
ggplot(aes(x = s.v, y = db.v)) +
geom_point()
apatite %>%
filter(s.v.ognp == "0") %>%
ggplot(aes(x = s.v, y = db.v)) +
geom_point()
apatite %>%
filter(s.v.ognp == "0")
View(apatite)
apatite %>%
filter(s.v.ognp == "term0") %>%
ggplot(aes(x = s.v, y = db.v)) +
geom_point()
apatite %>%
filter(s.v.ognp == "term0")
apatite %>%
filter(s.np.ognp == "term0") %>%
ggplot(aes(x = s.v, y = db.v)) +
geom_point()
apatite %>%
filter(np.ognp == "term0") %>%
ggplot(aes(x = s.v, y = db.v)) +
geom_point()
filter(apatite, np.npog == "0 ")
filter(apatite, np.ognp == "term0")
41/262
filter(apatite, np.ognp == "term1")
109/262
filter(apatite, np.ognp == "term2")
112/262
apatite %>%
filter(np.ognp == "term0") %>%
ggplot() +
geom_point(aes(x = s.v, y = db.v)) +
geom_point(aes(x = s.v.ognp, y = db.v)) +
geom_smoooth()
apatite %>%
filter(np.ognp == "term0") %>%
ggplot() +
geom_point(aes(x = s.v, y = db.v)) +
geom_point(aes(x = s.v.ognp, y = db.v)) +
geom_smooth()
apatite %>%
filter(np.ognp == "term0") %>%
ggplot() +
geom_point(aes(x = s.v, y = db.v)) +
geom_point(aes(x = s.v.ognp, y = db.v), color =  "blue")
apatite %>%
filter(np.ognp == "term0") %>%
ggplot() +
geom_point(aes(x = s.ft, y = db.ft)) +
geom_point(aes(x = s.ft.ognp, y = db.ft), color =  "blue")
apatite %>%
filter(np.ognp == "term0") %>%
ggplot() +
geom_point(aes(x = s.ft, y = db.ft)) +
geom_point(aes(x = s.ft.ognp, y = db.ft), color =  "blue")
phd_field <- readr::read_csv("https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-02-19/phd_by_field.csv")
# packages
library(tidyverse) # general data wrangling and plotting
# scripts
source("scripts/functions.R")
# global knitting options for code rendering
knitr::opts_chunk$set(
collapse = TRUE, comment = "#>",
dev = c("png", "pdf"),
dev.args = list(pdf = list(encoding = "WinAnsi", useDingbats = FALSE)),
fig.keep = "all",
fig.path = file.path("plots", paste0(gsub("\\.[Rr]md", "", knitr::current_input()), "_"))
)
# packages
library(tidyverse) # general data wrangling and plotting
# global knitting options for code rendering
knitr::opts_chunk$set(
collapse = TRUE, comment = "#>",
dev = c("png", "pdf"),
dev.args = list(pdf = list(encoding = "WinAnsi", useDingbats = FALSE)),
fig.keep = "all",
fig.path = file.path("plots", paste0(gsub("\\.[Rr]md", "", knitr::current_input()), "_"))
)
phd_field <- readr::read_csv("https://raw.githubusercontent.com/rfordatascience/tidytuesday/master/data/2019/2019-02-19/phd_by_field.csv")
head(phd_field)
summary(phd_fi)
summary(phd_field)
